const axios = require('axios');
const logger = require('../utils/logger');
const config = require('../config');

class ServiceClient {
  constructor(baseURL, serviceName) {
    this.client = axios.create({
      baseURL,
      timeout: 30000,
      headers: {
        'Content-Type': 'application/json',
        'User-Agent': 'workflow-engine-service/1.0.0'
      }
    });

    this.serviceName = serviceName;

    // ìš”ì²­ ì¸í„°ì…‰í„°
    this.client.interceptors.request.use(
      (config) => {
        logger.debug(`ğŸ“¡ ${this.serviceName} ìš”ì²­: ${config.method?.toUpperCase()} ${config.url}`);
        return config;
      },
      (error) => {
        logger.error(`âŒ ${this.serviceName} ìš”ì²­ ì˜¤ë¥˜:`, error);
        return Promise.reject(error);
      }
    );

    // ì‘ë‹µ ì¸í„°ì…‰í„°
    this.client.interceptors.response.use(
      (response) => {
        logger.debug(`âœ… ${this.serviceName} ì‘ë‹µ: ${response.status} ${response.config.url}`);
        return response;
      },
      (error) => {
        const message = error.response?.data?.message || error.message;
        logger.error(`âŒ ${this.serviceName} ì‘ë‹µ ì˜¤ë¥˜: ${error.response?.status} - ${message}`);
        return Promise.reject(error);
      }
    );
  }

  async healthCheck() {
    try {
      const response = await this.client.get('/health');
      return response.data;
    } catch (error) {
      return {
        status: 'unhealthy',
        error: error.message,
        timestamp: new Date().toISOString()
      };
    }
  }
}

class LLMServiceClient extends ServiceClient {
  constructor() {
    super(config.SERVICES.LLM, 'LLM Service');
  }

  // ğŸ”¥ LLM ì§ì ‘ ì±„íŒ… ë©”ì†Œë“œ (ê°„ë‹¨í•œ ë©”ì‹œì§€ìš©)
  async chat(message, options = {}) {
    try {
      const startTime = Date.now();
      logger.info(`ğŸ’¬ LLM ì§ì ‘ ì±„íŒ… ì‹œì‘: "${message}"`);
      
      const { sessionId, type = 'general', context = {} } = options;
      
      // ë©”ì‹œì§€ íƒ€ì…ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
      let systemPrompt = 'ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.';
      
      if (type === 'simple_conversation') {
        systemPrompt = 'ë‹¹ì‹ ì€ ì¹œê·¼í•œ ì¸í”„ë¼ ìë™í™” ì‹œìŠ¤í…œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ê°„ë‹¨í•˜ê³  ë”°ëœ»í•œ í†¤ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.';
      } else if (type === 'calculation') {
        systemPrompt = 'ë‹¹ì‹ ì€ ì •í™•í•œ ê³„ì‚°ê³¼ ìˆ˜í•™ ë¬¸ì œ í•´ê²°ì„ ë„ì™€ì£¼ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ê³„ì‚° ê³¼ì •ì„ ëª…í™•íˆ ì„¤ëª…í•˜ì„¸ìš”.';
      } else if (type === 'general_conversation') {
        systemPrompt = 'ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì¸í”„ë¼ ê´€ë¦¬ë‚˜ ê¸°ìˆ ì ì¸ ì§ˆë¬¸ì— ëŒ€í•´ì„œëŠ” ì „ë¬¸ì ìœ¼ë¡œ, ì¼ë°˜ì ì¸ ì§ˆë¬¸ì—ëŠ” ì¹œê·¼í•˜ê²Œ ì‘ë‹µí•˜ì„¸ìš”.';
      }

      const response = await this.client.post('/api/v1/llm/chat', {
        messages: [
          {
            role: 'system',
            content: systemPrompt
          },
          {
            role: 'user',
            content: message
          }
        ],
        temperature: 0.7,
        maxTokens: 500,
        model: 'gpt-3.5-turbo',
        sessionId: sessionId
      });

      const duration = Date.now() - startTime;
      const content = response.data.choices[0].message.content.trim();
      
      logger.info(`âœ… LLM ì§ì ‘ ì±„íŒ… ì™„ë£Œ (${duration}ms): "${content.substring(0, 50)}..."`);
      
      return {
        content: content,
        duration: duration,
        type: type,
        tokenUsage: response.data.usage || {}
      };

    } catch (error) {
      logger.error('âŒ LLM ì§ì ‘ ì±„íŒ… ì‹¤íŒ¨:', error);
      
      // í´ë°± ì‘ë‹µ ì œê³µ
      const fallbackResponses = {
        'simple_conversation': 'ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?',
        'calculation': 'ì£„ì†¡í•©ë‹ˆë‹¤. ê³„ì‚°ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
        'general_conversation': 'ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'
      };

      return {
        content: fallbackResponses[options.type] || 'ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
        duration: 0,
        type: 'fallback',
        error: error.message
      };
    }
  }

  // LLM ì±„íŒ… ìš”ì²­ (ì˜ë„ ë¶„ì„ìš©)
  async analyzeIntent(message, context = {}) {
    try {
      const startTime = Date.now();
      logger.info(`ğŸ” LLM ì˜ë„ ë¶„ì„ ì‹œì‘: "${message}"`);
      
      const response = await this.client.post('/api/v1/llm/chat', {
        messages: [
          {
            role: 'system',
            content: `ë‹¹ì‹ ì€ ì›Œí¬í”Œë¡œìš° ìë™í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”:

{
  "intent": "monitor_and_restart",
  "action": "monitor",
  "target": "web_servers", 
  "entities": {
    "threshold": 90,
    "service": "nginx",
    "metric": "cpu"
  },
  "confidence": 0.95,
  "category": "infrastructure"
}

ê°€ëŠ¥í•œ intent ê°’:
- monitor_and_restart: CPU/ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ í›„ ì¡°ê±´ë¶€ ì¬ì‹œì‘
- backup_data: ë°ì´í„° ë°±ì—… ìš”ì²­
- deploy_service: ì„œë¹„ìŠ¤ ë°°í¬ ìš”ì²­
- monitor_servers: ìƒíƒœ ëª¨ë‹ˆí„°ë§ë§Œ ìˆ˜í–‰
- restart_service: ì„œë¹„ìŠ¤ ì¬ì‹œì‘ë§Œ ìˆ˜í–‰
- general_inquiry: ì¼ë°˜ì ì¸ ì§ˆë¬¸ ë˜ëŠ” ëŒ€í™”

ë°˜ë“œì‹œ ìœ„ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.`
          },
          {
            role: 'user',
            content: `ì‚¬ìš©ì ìš”ì²­: "${message}"\nì»¨í…ìŠ¤íŠ¸: ${JSON.stringify(context)}`
          }
        ],
        temperature: 0.1,
        maxTokens: 300,
        model: 'gpt-3.5-turbo'
      });

      const duration = Date.now() - startTime;
      const content = response.data.choices[0].message.content.trim();
      logger.debug(`ğŸ’¬ LLM ì˜ë„ ë¶„ì„ ì‘ë‹µ: "${content}"`);
      
      try {
        // JSON í˜•ì‹ì„ ì°¾ì•„ì„œ íŒŒì‹±
        const jsonMatch = content.match(/\{[\s\S]*\}/);
        if (jsonMatch) {
          const parsed = JSON.parse(jsonMatch[0]);
          logger.info(`âœ… ì˜ë„ ë¶„ì„ ì„±ê³µ (${duration}ms):`, parsed);
          return parsed;
        } else {
          logger.warn(`âš ï¸ JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: "${content}"`);
          throw new Error('No JSON found in response');
        }
      } catch (parseError) {
        logger.warn(`âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: "${content}", í´ë°± ì‚¬ìš©`);
        return this.fallbackIntentAnalysis(message);
      }
    } catch (error) {
      logger.error('âŒ LLM ì˜ë„ ë¶„ì„ ì‹¤íŒ¨:', error);
      return this.fallbackIntentAnalysis(message);
    }
  }

  // ğŸ¯ ì›Œí¬í”Œë¡œìš° ì„ íƒì„ ìœ„í•œ LLM ë¶„ì„ (NEW)
  async analyzeWorkflowSelection(selectionData) {
    try {
      const startTime = Date.now();
      logger.info(`ğŸ¯ LLM ì›Œí¬í”Œë¡œìš° ì„ íƒ ë¶„ì„ ì‹œì‘`);
      
      const response = await this.client.post('/api/v1/llm/chat', {
        messages: [
          {
            role: 'system',
            content: `ë‹¹ì‹ ì€ IT ìë™í™” ì›Œí¬í”Œë¡œìš° ì„ íƒ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì„ íƒí•˜ê³  ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:

{
  "selectedWorkflowId": "ì„ íƒí•œ_ì›Œí¬í”Œë¡œìš°_ID",
  "confidence": 0.95,
  "reasoning": "ì„ íƒ ì´ìœ ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª…",
  "alternativeOptions": ["ëŒ€ì•ˆ_ì›Œí¬í”Œë¡œìš°_ID1", "ëŒ€ì•ˆ_ì›Œí¬í”Œë¡œìš°_ID2"],
  "expectedOutcome": "ì˜ˆìƒë˜ëŠ” ì‹¤í–‰ ê²°ê³¼"
}

ë§Œì•½ ì ì ˆí•œ ì›Œí¬í”Œë¡œìš°ê°€ ì—†ë‹¤ë©´:
{
  "selectedWorkflowId": null,
  "confidence": 0.0,
  "reasoning": "ì ì ˆí•œ ì›Œí¬í”Œë¡œìš°ê°€ ì—†ëŠ” ì´ìœ ",
  "suggestedAction": "ëŒ€ì•ˆ ì œì•ˆ"
}

ì„ íƒ ê¸°ì¤€:
1. ì‚¬ìš©ì ì˜ë„ì™€ ì›Œí¬í”Œë¡œìš° ê¸°ëŠ¥ì˜ ì •í™•í•œ ë§¤ì¹­
2. ì˜ˆìƒ ì„±ê³µë¥ ê³¼ ì•ˆì •ì„±
3. ì›Œí¬í”Œë¡œìš°ì˜ ë³µì¡ë„ì™€ ì‘ì—… ë²”ìœ„ì˜ ì ì ˆì„±`
          },
          {
            role: 'user',
            content: selectionData.prompt
          }
        ],
        temperature: 0.2,
        maxTokens: 500,
        model: 'gpt-3.5-turbo'
      });

      const duration = Date.now() - startTime;
      const content = response.data.choices[0].message.content.trim();
      
      try {
        const jsonMatch = content.match(/\{[\s\S]*\}/);
        if (jsonMatch) {
          const parsed = JSON.parse(jsonMatch[0]);
          logger.info(`âœ… ì›Œí¬í”Œë¡œìš° ì„ íƒ ë¶„ì„ ì™„ë£Œ (${duration}ms):`, {
            selectedId: parsed.selectedWorkflowId,
            confidence: parsed.confidence
          });
          return parsed;
        } else {
          throw new Error('No JSON found in response');
        }
      } catch (parseError) {
        logger.warn(`âš ï¸ ì›Œí¬í”Œë¡œìš° ì„ íƒ JSON íŒŒì‹± ì‹¤íŒ¨: "${content}"`);
        return {
          selectedWorkflowId: null,
          confidence: 0.0,
          reasoning: 'LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨',
          suggestedAction: 'ê·œì¹™ ê¸°ë°˜ ì„ íƒ ì‚¬ìš©'
        };
      }
    } catch (error) {
      logger.error('âŒ LLM ì›Œí¬í”Œë¡œìš° ì„ íƒ ë¶„ì„ ì‹¤íŒ¨:', error);
      return {
        selectedWorkflowId: null,
        confidence: 0.0,
        reasoning: `LLM ì„œë¹„ìŠ¤ ì˜¤ë¥˜: ${error.message}`,
        suggestedAction: 'ê·œì¹™ ê¸°ë°˜ ì„ íƒ ì‚¬ìš©'
      };
    }
  }

  // ê²°ê³¼ ê¸°ë°˜ ìì—°ì–´ ì‘ë‹µ ìƒì„±
  async generateResponse(message, results, intent) {
    try {
      const startTime = Date.now();
      logger.info(`ğŸ“ LLM ì‘ë‹µ ìƒì„± ì‹œì‘ for intent: ${intent?.intent}`);

      const systemPrompt = `ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ ì¸í”„ë¼ ìë™í™” ì‹œìŠ¤í…œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìš”ì²­ì— ëŒ€í•œ ì‘ì—… ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”.

ì‘ë‹µ ê°€ì´ë“œë¼ì¸:
1. ìˆ˜í–‰í•œ ì‘ì—…ì„ ëª…í™•íˆ ì„¤ëª…
2. ê²°ê³¼ë¥¼ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ìš”ì•½
3. í•„ìš”ì‹œ ë‹¤ìŒ ë‹¨ê³„ë‚˜ ê¶Œì¥ì‚¬í•­ ì œì‹œ
4. ì¹œê·¼í•˜ë©´ì„œë„ ì „ë¬¸ì ì¸ í†¤ ìœ ì§€
5. ê¸°ìˆ ì ì¸ ì„¸ë¶€ì‚¬í•­ì€ ì ì ˆíˆ ê°„ì†Œí™”`;

      const userContent = `
ì›ë³¸ ìš”ì²­: "${message}"
ë¶„ì„ëœ ì˜ë„: ${JSON.stringify(intent)}
ì‘ì—… ê²°ê³¼: ${JSON.stringify(results)}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì‘ë‹µì„ ìƒì„±í•´ì£¼ì„¸ìš”.`;

      const response = await this.client.post('/api/v1/llm/chat', {
        messages: [
          {
            role: 'system',
            content: systemPrompt
          },
          {
            role: 'user',
            content: userContent
          }
        ],
        temperature: 0.7,
        maxTokens: 500,
        model: 'gpt-3.5-turbo'
      });

      const duration = Date.now() - startTime;
      const content = response.data.choices[0].message.content.trim();
      
      logger.info(`âœ… LLM ì‘ë‹µ ìƒì„± ì™„ë£Œ (${duration}ms): "${content.substring(0, 100)}..."`);
      return content;

    } catch (error) {
      logger.error('âŒ LLM ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error);
      
      // í´ë°± ì‘ë‹µ ìƒì„±
      return this.generateFallbackResponse(message, results, intent);
    }
  }

  // ì—ëŸ¬ ìƒí™© ì‘ë‹µ ìƒì„±
  async generateErrorResponse(message, error) {
    try {
      const startTime = Date.now();
      logger.info(`âš ï¸ LLM ì—ëŸ¬ ì‘ë‹µ ìƒì„± ì‹œì‘`);

      const response = await this.client.post('/api/v1/llm/chat', {
        messages: [
          {
            role: 'system',
            content: `ë‹¹ì‹ ì€ ì¹œê·¼í•œ ì¸í”„ë¼ ìë™í™” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ì— ë°œìƒí•œ ë¬¸ì œë¥¼ ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”.
ì‚¬ìš©ìë¥¼ ì•ˆì‹¬ì‹œí‚¤ê³  ê°€ëŠ¥í•œ í•´ê²°ë°©ë²•ì´ë‚˜ ëŒ€ì•ˆì„ ì œì‹œí•˜ì„¸ìš”.`
          },
          {
            role: 'user',
            content: `ì‚¬ìš©ì ìš”ì²­: "${message}"
ë°œìƒí•œ ì˜¤ë¥˜: ${error.message || error}

ì´ ìƒí™©ì„ ì‚¬ìš©ìì—ê²Œ ì¹œê·¼í•˜ê²Œ ì„¤ëª…í•˜ê³  ê°€ëŠ¥í•œ í•´ê²°ë°©ë²•ì„ ì œì‹œí•´ì£¼ì„¸ìš”.`
          }
        ],
        temperature: 0.7,
        maxTokens: 300,
        model: 'gpt-3.5-turbo'
      });

      const duration = Date.now() - startTime;
      const content = response.data.choices[0].message.content.trim();
      
      logger.info(`âœ… LLM ì—ëŸ¬ ì‘ë‹µ ìƒì„± ì™„ë£Œ (${duration}ms)`);
      return content;

    } catch (llmError) {
      logger.error('âŒ LLM ì—ëŸ¬ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', llmError);
      
      // ìµœì¢… í´ë°± ì—ëŸ¬ ì‘ë‹µ
      return `ì£„ì†¡í•©ë‹ˆë‹¤. "${message}" ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì‹œê±°ë‚˜ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.`;
    }
  }

  // í´ë°± ì‘ë‹µ ìƒì„± (LLM í˜¸ì¶œ ì‹¤íŒ¨ì‹œ)
  generateFallbackResponse(message, results, intent) {
    const intentType = intent?.intent || 'unknown';
    
    logger.info(`ğŸ”„ í´ë°± ì‘ë‹µ ìƒì„± for intent: ${intentType}`);
    
    const fallbackTemplates = {
      monitor_servers: 'ì„œë²„ ìƒíƒœ í™•ì¸ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
      monitor_and_restart: 'ì„œë²„ ëª¨ë‹ˆí„°ë§ ë° ì¬ì‹œì‘ ì‘ì—…ì´ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.',
      restart_service: 'ì„œë¹„ìŠ¤ ì¬ì‹œì‘ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
      backup_data: 'ë°ì´í„° ë°±ì—… ì‘ì—…ì´ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.',
      deploy_service: 'ì„œë¹„ìŠ¤ ë°°í¬ ì‘ì—…ì´ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.',
      general_inquiry: 'ìš”ì²­ì´ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.',
      unknown: `"${message}" ìš”ì²­ì´ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.`
    };

    let response = fallbackTemplates[intentType] || fallbackTemplates.unknown;
    
    // ê²°ê³¼ê°€ ìˆìœ¼ë©´ ê°„ë‹¨íˆ ì¶”ê°€
    if (results && Array.isArray(results) && results.length > 0) {
      response += ` ${results.length}ê°œì˜ ì‘ì—…ì´ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.`;
    }
    
    return response;
  }

  // í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°± ì˜ë„ ë¶„ì„
  fallbackIntentAnalysis(message) {
    const lowerMessage = message.toLowerCase();
    
    logger.info(`ğŸ”„ í´ë°± ì˜ë„ ë¶„ì„ ì‚¬ìš©: "${message}"`);
    
    // CPU ëª¨ë‹ˆí„°ë§ ë° ì¬ì‹œì‘ íŒ¨í„´
    if ((lowerMessage.includes('cpu') || lowerMessage.includes('ì‚¬ìš©ë¥ ')) && 
        (lowerMessage.includes('ì¬ì‹œì‘') || lowerMessage.includes('restart'))) {
      return {
        intent: 'monitor_and_restart',
        action: 'monitor_and_restart',
        target: 'web_servers',
        entities: {
          metric: 'cpu',
          threshold: 90,
          service: 'nginx'
        },
        confidence: 0.8,
        category: 'infrastructure'
      };
    }
    
    // ì„œë²„ ëª¨ë‹ˆí„°ë§ íŒ¨í„´
    if (lowerMessage.includes('í™•ì¸') || lowerMessage.includes('ëª¨ë‹ˆí„°ë§') || 
        lowerMessage.includes('ìƒíƒœ') || lowerMessage.includes('status')) {
      return {
        intent: 'monitor_servers',
        action: 'monitor',
        target: 'web_servers',
        entities: {
          metric: 'status'
        },
        confidence: 0.7,
        category: 'infrastructure'
      };
    }
    
    // ì¬ì‹œì‘ íŒ¨í„´
    if (lowerMessage.includes('ì¬ì‹œì‘') || lowerMessage.includes('restart')) {
      return {
        intent: 'restart_service',
        action: 'restart',
        target: 'web_servers',
        entities: {
          service: 'nginx'
        },
        confidence: 0.7,
        category: 'infrastructure'
      };
    }
    
    // ë°±ì—… íŒ¨í„´
    if (lowerMessage.includes('ë°±ì—…') || lowerMessage.includes('backup')) {
      return {
        intent: 'backup_data',
        action: 'backup',
        target: 'all_servers',
        entities: {},
        confidence: 0.7,
        category: 'infrastructure'
      };
    }
    
    // ê¸°ë³¸ ëŒ€í™” íŒ¨í„´
    return {
      intent: 'general_inquiry',
      action: 'respond',
      target: 'system',
      entities: { original_message: message },
      confidence: 0.5,
      category: 'general'
    };
  }

  // ê²°ê³¼ ìš”ì•½ ìƒì„±
  async generateSummary(executionResult, workflowName) {
    try {
      const response = await this.client.post('/api/v1/llm/chat', {
        messages: [
          {
            role: 'system',
            content: 'ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.'
          },
          {
            role: 'user',
            content: `ì›Œí¬í”Œë¡œìš° "${workflowName}" ì‹¤í–‰ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê²°ê³¼: ${JSON.stringify(executionResult)}`
          }
        ],
        temperature: 0.7,
        maxTokens: 300
      });

      return response.data.choices[0].message.content;
    } catch (error) {
      logger.error('âŒ LLM ìš”ì•½ ìƒì„± ì‹¤íŒ¨:', error);
      return `ì›Œí¬í”Œë¡œìš° "${workflowName}" ì‹¤í–‰ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.`;
    }
  }
}

class MCPServiceClient extends ServiceClient {
  constructor() {
    super(config.SERVICES.MCP, 'MCP Service');
  }

  // MCP ë„êµ¬ ì‹¤í–‰
  async executeTool(serverId, tool, params, async = true) {
    try {
      const response = await this.client.post('/api/v1/mcp/execute', {
        serverId,
        tool,
        params,
        async
      });

      return response.data;
    } catch (error) {
      logger.error(`âŒ MCP ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨: ${tool}`, error);
      throw error;
    }
  }

  // MCP ì‹¤í–‰ ìƒíƒœ ì¡°íšŒ
  async getExecutionStatus(executionId) {
    try {
      const response = await this.client.get(`/api/v1/mcp/executions/${executionId}`);
      return response.data;
    } catch (error) {
      logger.error(`âŒ MCP ì‹¤í–‰ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: ${executionId}`, error);
      throw error;
    }
  }

  // ì‚¬ìš© ê°€ëŠ¥í•œ MCP ì„œë²„ ëª©ë¡
  async getServers() {
    try {
      const response = await this.client.get('/api/v1/mcp/servers');
      return response.data;
    } catch (error) {
      logger.error('âŒ MCP ì„œë²„ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:', error);
      throw error;
    }
  }

  // ì„œë²„ë³„ ë„êµ¬ ëª©ë¡
  async getServerTools(serverId) {
    try {
      const response = await this.client.get(`/api/v1/mcp/servers/${serverId}/tools`);
      return response.data;
    } catch (error) {
      logger.error(`âŒ MCP ì„œë²„ ë„êµ¬ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: ${serverId}`, error);
      throw error;
    }
  }
}

class DeviceServiceClient extends ServiceClient {
  constructor() {
    super(config.SERVICES.DEVICE, 'Device Service');
  }

  // ì¥ë¹„ ëª©ë¡ ì¡°íšŒ
  async getDevices(filters = {}) {
    try {
      const response = await this.client.get('/api/v1/devices', { params: filters });
      return response.data;
    } catch (error) {
      logger.error('âŒ ì¥ë¹„ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:', error);
      throw error;
    }
  }

  // íŠ¹ì • ì¥ë¹„ ìƒíƒœ ì¡°íšŒ
  async getDeviceStatus(deviceId) {
    try {
      const response = await this.client.get(`/api/v1/devices/${deviceId}/status`);
      return response.data;
    } catch (error) {
      logger.error(`âŒ ì¥ë¹„ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: ${deviceId}`, error);
      throw error;
    }
  }

  // ì¥ë¹„ ë©”íŠ¸ë¦­ ì¡°íšŒ
  async getDeviceMetrics(deviceId, metric = null, timeRange = {}) {
    try {
      const params = { ...timeRange };
      if (metric) params.metric = metric;

      const response = await this.client.get(`/api/v1/devices/${deviceId}/metrics`, { params });
      return response.data;
    } catch (error) {
      logger.error(`âŒ ì¥ë¹„ ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨: ${deviceId}`, error);
      throw error;
    }
  }

  // ê·¸ë£¹ë³„ ì¥ë¹„ ì¡°íšŒ
  async getDevicesByGroup(groupName) {
    try {
      const response = await this.client.get('/api/v1/devices', {
        params: { groupName }
      });
      return response.data;
    } catch (error) {
      logger.error(`âŒ ê·¸ë£¹ë³„ ì¥ë¹„ ì¡°íšŒ ì‹¤íŒ¨: ${groupName}`, error);
      throw error;
    }
  }
}

// í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ë“¤
const llmClient = new LLMServiceClient();
const mcpClient = new MCPServiceClient();
const deviceClient = new DeviceServiceClient();

module.exports = {
  LLMServiceClient,
  MCPServiceClient,
  DeviceServiceClient,
  llmClient,
  mcpClient,
  deviceClient
};